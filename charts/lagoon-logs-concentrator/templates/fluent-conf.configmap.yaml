apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "lagoon-logs-concentrator.fullname" . }}-fluent-conf
  labels:
    {{- include "lagoon-logs-concentrator.labels" . | nindent 4 }}
data:
  fluent.conf: |
    # vi: ft=fluentd
    <system>
      workers 4
      # set to error because fluentd is quite chatty about to liveness probes
      log_level error
    </system>
    # prometheus metrics
    <source>
      @type prometheus
    </source>
    <source>
      @type prometheus_monitor
    </source>
    <source>
      @type prometheus_output_monitor
    </source>
    <source>
      @type          forward
      @id            in_forward
      add_tag_prefix in_forward
      <security>
        self_hostname logs-concentrator
        user_auth true
        shared_key "#{ENV['FORWARD_SHARED_KEY']}"
        @include user.d/*.conf
      </security>
      <transport tls>
        ca_path /fluentd/tls/ca.crt
        cert_path /fluentd/tls/server.crt
        private_key_path /fluentd/tls/server.key
        client_cert_auth true
      </transport>
    </source>

    # prometheus monitoring
    <filter in_forward.**>
      @type prometheus
      <metric>
        name fluentd_input_status_num_records_total
        type counter
        desc The total number of incoming records
        <labels>
          tag ${tag}
          hostname ${hostname}
        </labels>
      </metric>
    </filter>

    # send to opensearch
    <match in_forward.**>
      @type opensearch
      @id out_opensearch
      # be more verbose about opensearch problems
      @log_level info
      # ingestion
      target_index_key index_name
      include_timestamp true
      time_key time
      # endpoint
      host "#{ENV['OPENSEARCH_HOST']}"
      port "#{ENV.fetch('OPENSEARCH_HOST_PORT','9200')}"
      scheme "#{ENV.fetch('OPENSEARCH_SCHEME','http')}"
      ssl_min_version TLSv1_2
      ssl_max_version TLSv1_3
      user "#{ENV['LOGSDB_ADMIN_USER']}"
      password "#{ENV['LOGSDB_ADMIN_PASSWORD']}"
      # endpoint error handling
      reconnect_on_error true
      # never reload - always use the configured host only
      reload_on_failure false
      reload_connections false
      request_timeout 600s
      slow_flush_log_threshold 300s
      log_es_400_reason true
      <buffer tag,index_name>
        @type file
        path /fluentd/buffer/opensearch
        # buffer params (per worker)
        total_limit_size 8GB
        # flush params
        flush_thread_count 8              # make sure we have plenty of flush threads for all the different buffers
        flush_interval 10s                # flush every 10 secs
        flush_thread_burst_interval 0     # don't sleep if there are more chunks to be flushed
        retry_max_interval 30s            # limit exponential backoff period
        retry_timeout 12h                 # limit the time spent retrying chunk submission
        chunk_limit_size 32MB             # chunks cannot be bigger than the max HTTP limit of Opensearch (which is 100MB)
        overflow_action drop_oldest_chunk # drop chunks once they reach retry limits
      </buffer>
      # silence warnings (these have no effect)
      type_name _doc
      suppress_type_name true
      ssl_version TLSv1_2
{{- if not .Values.opensearchTLSVerify }}
      ssl_verify false
{{- end }}
{{- if not .Values.verifyOSVersionAtStartup }}
      verify_os_version_at_startup false
{{- end }}
{{- if .Values.opensearchCACert }}
      ca_file /fluentd/es-tls/ca.crt
{{- end }}
    </match>
