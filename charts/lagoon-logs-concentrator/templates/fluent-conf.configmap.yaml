apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "lagoon-logs-concentrator.fullname" . }}-fluent-conf
  labels:
    {{- include "lagoon-logs-concentrator.labels" . | nindent 4 }}
data:
  fluent.conf: |
    # vi: ft=fluentd
    <system>
      workers 4
    </system>
    # prometheus metrics
    <source>
      @type prometheus
    </source>
    <source>
      @type prometheus_monitor
    </source>
    <source>
      @type prometheus_output_monitor
    </source>
    <source>
      @type          forward
      @id            in_forward
      add_tag_prefix in_forward
      # avoid verbose OpenSSL warnings in fluentd logs due to liveness probes
      # @log_level      error
      <security>
        self_hostname logs-concentrator
        user_auth true
        shared_key "#{ENV['FORWARD_SHARED_KEY']}"
        @include user.d/*.conf
      </security>
      <transport tls>
        ca_path /fluentd/tls/ca.crt
        cert_path /fluentd/tls/server.crt
        private_key_path /fluentd/tls/server.key
        client_cert_auth true
      </transport>
    </source>

    # prometheus monitoring
    <filter in_forward.**>
      @type prometheus
      <metric>
        name fluentd_input_status_num_records_total
        type counter
        desc The total number of incoming records
        <labels>
          tag ${tag}
          hostname ${hostname}
        </labels>
      </metric>
    </filter>


    # send to elasticsearch
    <match in_forward.**>
      @type elasticsearch
      @id out_elasticsearch
      # ingestion
      target_index_key index_name
      include_timestamp true
      time_key time
      # endpoint
      host "#{ENV['ELASTICSEARCH_HOST']}"
      port "#{ENV.fetch('ELASTICSEARCH_HOST_PORT','9200')}"
      scheme "#{ENV.fetch('ELASTICSEARCH_SCHEME','http')}"
      ssl_min_version TLSv1_2
      ssl_max_version TLSv1_3
      user admin
      password "#{ENV['LOGSDB_ADMIN_PASSWORD']}"
      # endpoint error handling
      reconnect_on_error true
      reload_on_failure true
      request_timeout 600s
      slow_flush_log_threshold 300s
      log_es_400_reason true
      <buffer tag,index_name>
        @type file
        path /fluentd/buffer/elasticsearch
        # buffer params (per worker)
        total_limit_size 8GB
        # flush params
        flush_thread_count 8 # 8 threads that flush, makes sure we have enough flushers for all the different buffers
        flush_interval 10s # flush every 10 secs
        flush_thread_burst_interval 0 # don't sleep if there is more chunks to be flushed
        retry_max_interval 30s # limit exponential backoff period
        chunk_limit_size 32MB # chunks cannot be bigger than the max HTTP limit of Elasticsearch (which is 100MB)
        overflow_action drop_oldest_chunk
      </buffer>
      # silence warnings (these have no effect)
      type_name _doc
      suppress_type_name true
      ssl_version TLSv1_2
{{- if not .Values.verifyESVersionAtStartup }}
      verify_es_version_at_startup false
{{- end }}
    </match>
