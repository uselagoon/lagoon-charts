## Create default rules for monitoring the cluster
##

commonLabels:
  lagoon.sh/component: monitoring
  monitoring.lagoon.sh/monitorMe: "true"

defaultRules:
  create: true
  rules:
    prometheus: true
    general: true

    alertmanager: false
    etcd: false
    k8s: false
    kubeApiserver: false
    kubeApiserverAvailability: false
    kubeApiserverError: false
    kubeApiserverSlos: false
    kubelet: false
    kubePrometheusGeneral: false
    kubePrometheusNodeAlerting: false
    kubePrometheusNodeRecording: false
    kubernetesAbsent: false
    kubernetesApps: false
    kubernetesResources: false
    kubernetesStorage: false
    kubernetesSystem: false
    kubeScheduler: false
    kubeStateMetrics: false
    network: false
    node: false
    prometheusOperator: false
    time: false

## Configuration for alertmanager
## ref: https://prometheus.io/docs/alerting/alertmanager/
##
alertmanager:

  ## Deploy alertmanager
  ##
  enabled: true

  ingress:
    enabled: true
    annotations:
      kubernetes.io/tls-acme: "true"
    {{- if .Values.auth.enabled }}
      nginx.ingress.kubernetes.io/auth-signin: "https://{{ .Values.auth.host }}/login?url=$scheme://$http_host$request_uri&vouch-failcount=$auth_resp_failcount&X-Vouch-Token=$auth_resp_jwt&error=$auth_resp_err"
      nginx.ingress.kubernetes.io/auth-url: https://{{ .Values.auth.host }}/validate
      nginx.ingress.kubernetes.io/auth-response-headers: X-Vouch-User
      nginx.ingress.kubernetes.io/auth-snippet: |
        # these return values are used by the @error401 call
        auth_request_set $auth_resp_jwt $upstream_http_x_vouch_jwt;
        auth_request_set $auth_resp_err $upstream_http_x_vouch_err;
        auth_request_set $auth_resp_failcount $upstream_http_x_vouch_failcount;
    {{- end }}
    hosts:
      - {{ .Values.alertmanager.host }}
    path: /
    tls:
    - secretName: {{ .Values.alertmanager.host }}-tls
      hosts:
      - {{ .Values.alertmanager.host }}

  alertmanagerSpec:
    externalUrl: https://{{ .Values.alertmanager.host }}

  config:
    route:
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 4h
      group_by: ['cluster', 'alertname', 'service', 'namespace']
      receiver: slack_amazeeio_alertmanager_normal
      # The child route trees
      routes:
      - match:
          alertname: Watchdog
        repeat_interval: 5m
        receiver: deadmanssnitch
      - match:
          severity: critical
        receiver: slack_amazeeio_alertmanager_critical
      - match:
          severity: warning
        receiver: slack_amazeeio_alertmanager_warning
    # Inhibition rules allow to mute a set of alerts given that another alert is
    # firing.
    # We use this to mute any warning-level notifications if the same alert is
    # already critical.
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      # Apply inhibition if the alertname is the same.
      equal: ['alertname', 'cluster', 'service']
    receivers:
    - name: slack_amazeeio_alertmanager_critical
      slack_configs:
      - api_url: {{ .Values.alertmanager.slack.apiUrl }}
        channel: '{{ .Values.alertmanager.slack.channel }}'
        send_resolved: true
        username: {{ .Values.alertmanager.slack.username }}
        color: '{{ `{{ if eq .Status "firing" }}` }}danger{{ `{{ else }}` }}good{{ `{{ end }}` }}'
        title: |-
          [{{ `{{ .Status | toUpper }}` }}{{ `{{ if eq .Status "firing" }}` }}:{{ `{{ .Alerts.Firing | len }}` }}{{ `{{ end }}` }}] {{ `{{ .CommonLabels.alertname }}` }}
        text: '{{ `{{ template "slack.amazeeio.text" . }}` }}'
    - name: slack_amazeeio_alertmanager_warning
      slack_configs:
      - api_url: {{ .Values.alertmanager.slack.apiUrl }}
        channel: '{{ .Values.alertmanager.slack.channel }}'
        send_resolved: false
        username: {{ .Values.alertmanager.slack.username }}
        color: '{{ `{{ if eq .Status "firing" }}` }}warning{{ `{{ else }}` }}good{{ `{{ end }}` }}'
        title: |-
          [{{ `{{ .Status | toUpper }}` }}{{ `{{ if eq .Status "firing" }}` }}:{{ `{{ .Alerts.Firing | len }}` }}{{ `{{ end }}` }}] {{ `{{ .CommonLabels.alertname }}` }}
        text: '{{ `{{ template "slack.amazeeio.text" . }}` }}'
    - name: slack_amazeeio_alertmanager_normal
      slack_configs:
      - api_url: {{ .Values.alertmanager.slack.apiUrl }}
        channel: '{{ .Values.alertmanager.slack.channel }}'
        send_resolved: true
        username: {{ .Values.alertmanager.slack.username }}
        color: 'good'
        title: |-
          [{{ `{{ .Status | toUpper }}` }}{{ `{{ if eq .Status "firing" }}` }}:{{ `{{ .Alerts.Firing | len }}` }}{{ `{{ end }}` }}] {{ `{{ .CommonLabels.alertname }}` }}
        text: '{{ `{{ template "slack.amazeeio.text" . }}` }}'
    - name: deadmanssnitch
      webhook_configs:
      - send_resolved: false
        url: {{ .Values.alertmanager.littlesnitch.url }}
    templates:
      - '/etc/alertmanager/config/slack.tmpl'
  templateFiles:
    slack.tmpl: |-
        {{ `{{ define "cluster" }}` }}{{ `{{ .ExternalURL | reReplaceAll ".*alertmanager\\.(.*)" "$1" }}` }}{{ `{{ end }}` }}

        {{ `{{ define "slack.amazeeio.text" }}` }}
        {{ `{{- $root := . -}}` }}
        {{ `{{ range .Alerts }}` }}
          *Alert:* {{ `{{ .Annotations.summary }}` }} - `{{ `{{ .Labels.severity }}` }}`
          *Cluster:*  {{ `{{ template "cluster" $root }}` }}
          *Description:* {{ `{{ .Annotations.description }}` }}
          *Graph:* <{{ `{{ .GeneratorURL }}` }}|:chart_with_upwards_trend:>
          *Runbook:* <{{ `{{ .Annotations.runbook }}` }}|:spiral_note_pad:>
          *Details:*
            {{ `{{ range .Labels.SortedPairs }}` }} â€¢ *{{ `{{ .Name }}` }}:* `{{ `{{ .Value }}` }}`
            {{ `{{ end }}` }}
        {{ `{{ end }}` }}
        {{ `{{ end }}` }}

## Using default values from https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
##
grafana:
  enabled: true
  defaultDashboardsEnabled: false
  ingress:
    enabled: true
    annotations:
      kubernetes.io/tls-acme: "true"
    {{- if .Values.auth.enabled }}
      nginx.ingress.kubernetes.io/auth-signin: "https://{{ .Values.auth.host }}/login?url=$scheme://$http_host$request_uri&vouch-failcount=$auth_resp_failcount&X-Vouch-Token=$auth_resp_jwt&error=$auth_resp_err"
      nginx.ingress.kubernetes.io/auth-url: https://{{ .Values.auth.host }}/validate
      nginx.ingress.kubernetes.io/auth-response-headers: X-Vouch-User
      nginx.ingress.kubernetes.io/auth-snippet: |
        # these return values are used by the @error401 call
        auth_request_set $auth_resp_jwt $upstream_http_x_vouch_jwt;
        auth_request_set $auth_resp_err $upstream_http_x_vouch_err;
        auth_request_set $auth_resp_failcount $upstream_http_x_vouch_failcount;
    {{- end }}
    hosts:
      - {{ .Values.grafana.host }}
    path: /
    tls:
    - secretName: {{ .Values.grafana.host }}-tls
      hosts:
      - {{ .Values.grafana.host }}

  grafana.ini:
    server:
      root_url: https://{{ .Values.grafana.host }}
    auth.anonymous:
      enabled: true
      org_role: Admin
      org_name: Main Org.

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'grafana-com'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/grafana-com

  dashboards:
    grafana-com:
      prometheus-stats:
        gnetId: 2
        revision: 2
        datasource: Prometheus
      loggin-operator:
        gnetId: 7752
        revision: 4
        datasource: Prometheus
      alertmanager:
        gnetId: 9578
        revision: 4
        datasource: Prometheus
      grafana:
        gnetId: 3590
        revision: 3
        datasource: Prometheus
      nginx-ingress:
        gnetId: 9614
        revision: 1
        datasource: Prometheus
{{- toYaml .Values.grafana.dashboards | nindent 6 }}

## Component scraping the kube api server
##
kubeApiServer:
  enabled: false


## Component scraping the kubelet and kubelet-hosted cAdvisor
##
kubelet:
  enabled: false


## Component scraping the kube controller manager
##
kubeControllerManager:
  enabled: false


## Component scraping coreDns. Use either this or kubeDns
##
coreDns:
  enabled: false

## Component scraping kubeDns. Use either this or coreDns
##
kubeDns:
  enabled: false


## Component scraping etcd
##
kubeEtcd:
  enabled: false


## Component scraping kube scheduler
##
kubeScheduler:
  enabled: false

## Component scraping kube proxy
##
kubeProxy:
  enabled: false

## Component scraping kube state metrics
##
kubeStateMetrics:
  enabled: false

## Deploy node exporter as a daemonset to all nodes
##
nodeExporter:
  enabled: false

## Manages Prometheus and Alertmanager components
##
prometheusOperator:
  enabled: false
  manageCrds: false
  createCustomResource: false

  admissionWebhooks:
    enabled: false

## Deploy a Prometheus instance
##
prometheus:

  enabled: true

  prometheusSpec:
    serviceMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelector:
      matchLabels:
        monitoring.lagoon.sh/monitorMe: "true"

    podMonitorSelectorNilUsesHelmValues: false
    podMonitorSelector:
      matchLabels:
        monitoring.lagoon.sh/monitorMe: "true"

    ruleSelectorNilUsesHelmValues: false
    ruleSelector:
      matchLabels:
        monitoring.lagoon.sh/monitorMe: "true"

    storageSpec:
     volumeClaimTemplate:
       spec:
         accessModes: ["ReadWriteOnce"]
         resources:
           requests:
             storage: 200Gi

    externalUrl: "https://{{ .Values.prometheus.host }}"

  ingress:
    enabled: true
    annotations:
      kubernetes.io/tls-acme: "true"
    {{- if .Values.auth.enabled }}
      nginx.ingress.kubernetes.io/auth-signin: "https://{{ .Values.auth.host }}/login?url=$scheme://$http_host$request_uri&vouch-failcount=$auth_resp_failcount&X-Vouch-Token=$auth_resp_jwt&error=$auth_resp_err"
      nginx.ingress.kubernetes.io/auth-url: https://{{ .Values.auth.host }}/validate
      nginx.ingress.kubernetes.io/auth-response-headers: X-Vouch-User
      nginx.ingress.kubernetes.io/auth-snippet: |
        # these return values are used by the @error401 call
        auth_request_set $auth_resp_jwt $upstream_http_x_vouch_jwt;
        auth_request_set $auth_resp_err $upstream_http_x_vouch_err;
        auth_request_set $auth_resp_failcount $upstream_http_x_vouch_failcount;
      {{- end }}
    hosts:
      - {{ .Values.prometheus.host }}
    path: /
    tls:
    - secretName: {{ .Values.prometheus.host }}-tls
      hosts:
      - {{ .Values.prometheus.host }}
